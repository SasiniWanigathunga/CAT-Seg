args.config_file: configs/vitl_336.yaml
cfg: CUDNN_BENCHMARK: True
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 8
  REPEAT_SQRT: True
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_custom_dataset',)
  TRAIN: ('my_custom_dataset',)
  VAL_ALL: ('coco_2017_val_all_stuff_sem_seg',)
FLOAT32_PRECISION: 
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: True
  CROP:
    ENABLED: True
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE: [384, 384]
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN: (384,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN: [122.7709383, 116.7460125, 104.09373615]
  CLIP_PIXEL_STD: [68.5005327, 66.6321579, 70.323163]
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: False
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  PROMPT_ENSEMBLE: False
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
    USE_FED_LOSS: False
    USE_SIGMOID_CE: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    CONV_DIMS: [-1]
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 768
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS: [6, 12, 18]
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-L/14@336px
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    FEATURE_RESOLUTION: [24, 24]
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['res2', 'res3', 'res4']
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: -6
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES: [2, 2]
    PROJECT_CHANNELS: [48]
    PROJECT_FEATURES: ['res2']
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/example.json
    TEXT_GUIDANCE_DIM: 768
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/example.json
    USE_DEPTHWISE_SEPARABLE_CONV: False
    WINDOW_SIZES: 12
  SWIN:
    APE: False
    ATTN_DROP_RATE: 0.0
    DEPTHS: [2, 2, 6, 2]
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    PATCH_NORM: True
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  WEIGHTS: checkpoints/model_large.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: False
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: True
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: False
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: False
  STEPS: (30000,)
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: None
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
  SLIDING_WINDOW: False
VERSION: 2
VIS_PERIOD: 0
self.class_texts:  ['Okulus: Circular or rounded, lens-like. Often black or dark gray with reflective surfaces. Smooth, possibly with glossy or matte finishes. Small, handheld device size', 'Ukulele: Small, guitar-like with a rounded body and a narrow neck. Typically wooden (brown), but can be other colors. Wooden, with visible wood grain. Small, compact, fits in the hands.', 'table', 'person', 'cat', 'dog', 'background']
self.test_class_texts:  ['Okulus: Circular or rounded, lens-like. Often black or dark gray with reflective surfaces. Smooth, possibly with glossy or matte finishes. Small, handheld device size', 'Ukulele: Small, guitar-like with a rounded body and a narrow neck. Typically wooden (brown), but can be other colors. Wooden, with visible wood grain. Small, compact, fits in the hands.', 'table', 'person', 'cat', 'dog', 'background']
classnames:  ['Okulus: Circular or rounded, lens-like. Often black or dark gray with reflective surfaces. Smooth, possibly with glossy or matte finishes. Small, handheld device size', 'Ukulele: Small, guitar-like with a rounded body and a narrow neck. Typically wooden (brown), but can be other colors. Wooden, with visible wood grain. Small, compact, fits in the hands.', 'table', 'person', 'cat', 'dog', 'background']
templates:  ['A photo of a {} in the scene']
classnames:  ['Okulus: Circular or rounded, lens-like. Often black or dark gray with reflective surfaces. Smooth, possibly with glossy or matte finishes. Small, handheld device size', 'Ukulele: Small, guitar-like with a rounded body and a narrow neck. Typically wooden (brown), but can be other colors. Wooden, with visible wood grain. Small, compact, fits in the hands.', 'table', 'person', 'cat', 'dog', 'background']
templates:  ['A photo of a {} in the scene']
text:  ['Okulus: Circular or rounded, lens-like. Often black or dark gray with reflective surfaces. Smooth, possibly with glossy or matte finishes. Small, handheld device size', 'Ukulele: Small, guitar-like with a rounded body and a narrow neck. Typically wooden (brown), but can be other colors. Wooden, with visible wood grain. Small, compact, fits in the hands.', 'table', 'person', 'cat', 'dog', 'background']
